{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollar un notebook de Jupyter, denominado “hashtags.ipynb”, en el que se utilice como fuente de datos Kafka, y en concreto el topic kafkaTwitter. \n",
    "\n",
    "La duración del batch será de 5 segundos. \n",
    "\n",
    "Se procesarán los tweets que lleguen para extraer los hashtags que contengan (tener en cuenta que todos los hashtags comienzan por el carácter ‘#’).\n",
    "\n",
    "Se irán mostrando, cada vez que se procese el batch (5 segundos) los diez hashtags más utilizados desde el inicio del programa hasta ese momento y el número total de apariciones de cada uno, ordenados de mayor a menor frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import requests\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from collections import namedtuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializo spark\n",
    "findspark.init('/home/j/spark-2.4.7-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesario para spark streaming y kafka\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.4.7 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del nombre del topic\n",
    "topic = 'kafkaTwitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialización de los contextos de Spark\n",
    "sc = SparkContext(\"local[*]\")\n",
    "ssc = StreamingContext(sc, 5)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialización del Dstream de kafka\n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        'bootstrap.servers':'localhost:9092, localhost:9093',\n",
    "                        'group.id':'test-group'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ventana de recepción de tweets de 20 segundos\n",
    "lines = kafkaStream.window( 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estructura de la tupla tweets: tags / count\n",
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los tweets\n",
    "( lines.flatMap( lambda text: text[1].split( \" \" ) ) # Dividimos por espacio\n",
    "  .filter( lambda word: word.lower().startswith(\"#\") ) # Obtenemos los tags\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # transformamos a minúsculas la palabra\n",
    "  .reduceByKey( lambda a, b: a + b ) # reducimos\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # almacenamos en un objeto Tweet\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) # Los ordenamos en un DataFrame\n",
    "  .limit(10).registerTempTable(\"tweets\") ) ) # registrado en una tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamos stream\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    count\n",
      "tag                      \n",
      "#forocambio11j         26\n",
      "#ciencia               15\n",
      "#internet              14\n",
      "#arte                   8\n",
      "#uam                    8\n",
      "#summerslam             8\n",
      "#tuitutil               6\n",
      "#orgullo2015            5\n",
      "#cmin                   4\n",
      "#estudiantes            4\n",
      "#mtvhottest             2\n",
      "#empleo                 2\n",
      "#errejónenrne           2\n",
      "#guipúzcoa              1\n",
      "#xespaña”               1\n",
      "#xelfuturodeespaña      1\n",
      "#competencias,          1\n",
      "#destacada              1\n",
      "#tipografía             1\n",
      "#tablondeanuncios       1\n",
      "#rai                    1\n",
      "#minecraft              1\n",
      "#propuestas             1\n",
      "#pc                     1\n",
      "#osx                    1\n",
      "#noestoyllorando        1\n",
      "#fans                   1\n",
      "#msg4321...en           1\n",
      "#zumba                  1\n"
     ]
    }
   ],
   "source": [
    "# creación de dataframe que contendrá el top\n",
    "top_total = pd.DataFrame()\n",
    "\n",
    "# ejecución mientras sea True\n",
    "while True:\n",
    "    # ponemos un sleep entre ejecuciones\n",
    "    time.sleep( 3 )\n",
    "    \n",
    "    # guardamos el top de tweets con tag y count\n",
    "    top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )\n",
    "    \n",
    "    # pasamos a dataframe el top\n",
    "    top_10_df = top_10_tweets.toPandas()\n",
    "    \n",
    "    # acumulamos a un top total para tener el resultado esperado del ejercicio\n",
    "    top_total = top_total.append(top_10_df)\n",
    "    \n",
    "    # imprimimos\n",
    "    print(top_total.groupby(['tag']).sum().sort_values('count', ascending=False))\n",
    "    \n",
    "    # borramos entre ejecuciones para ir viendo el resultado acumulado nada mas\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # nota: dejo un output para que se vea la ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
