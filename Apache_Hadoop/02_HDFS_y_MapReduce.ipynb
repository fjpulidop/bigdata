{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es HDFS?\n",
    "- Hadoop Distributed File System (HDFS)\n",
    "    - Sistema de archivos distribuido y tolerante a fallos\n",
    "    - Alta disponibilidad y altas prestaciones\n",
    "    - Accesible mediante línea de comandos e interfaz gráfico\n",
    "    - Escalable\n",
    "    - Coherencia de datos: WORM (Write Once, Read Many)\n",
    "    - Portable a diferentes piezas de hardware y software\n",
    "    \n",
    "## Arquitectura de HDFS\n",
    "![02_hadoop_1]\n",
    "\n",
    "- NameNode\n",
    "    - El servidor maestro que coordina todo el trabajo del cluster HDFS\n",
    "    - No almacena datos, solamente metadatos (<bloque, nodo>, ...)\n",
    "    - Implementa alta disponibilidad mediante un segundo NameNode que permanece en standby y que está al tanto de las actualizaciones del sistema\n",
    "    \n",
    "- DataNodes\n",
    "    - Almacenan los datos\n",
    "    - Envía heartbeats al NameNode\n",
    "    - Cuando un DataNode no envía heartbeat, el NameNode lo marca como muerto e inicia la replicación de los datos a otros DataNodes\n",
    "    \n",
    "## Escrituras en HDFS\n",
    "- Un fichero de gran tamaño será divido en unidades denominadas \"bloques\".\n",
    "- Cada bloque será copiado en 1-N nodos (factor de replicación)\n",
    "    - De tal forma que en un nodo podremos tener 1-N \"bloques\"\n",
    "- Los DataNodes que almacenarán cada bloque se seleccionan teniendo en cuenta, entre otros aspectos, su localización en la red (\"rack-awareness\").\n",
    "\n",
    "## Lecturas en HDFS\n",
    "- Se pregunta desde cliente dónde está el fichero X al NameNode\n",
    "- El NameNode reconoce que este fichero está dividido en N bloques repartidos en N nodos\n",
    "- El namenode devuelve el fichero\n",
    "- Para seleccionar el DataNode del que leer, se elege el más cercano\n",
    "- Para ello se calculan las distancias, donde existen los siguientes niveles:\n",
    "    - Diferentes procesos en el mismo nodo\n",
    "    - Diferentes nodos en el mismo rack\n",
    "    - Nodos en distintos racks del mismo datacenter\n",
    "    - Nodos en diferentes datacenters\n",
    "- Por ejemplo, sea el nodo n1, del rack r1, del datacenter d1 (representado como /d1/r1/n1). En este escenario:\n",
    "    - distancia (/d1/r1/n1, /d1/r1/n1) = 0 (procesos en el mismo nodo)\n",
    "    - distancia (/d1/r1/n1, /d1/r2/n2) = 2 (diferentes nodos del mismo rack)\n",
    "    - distancia (/d1/r1/n1, /d1/r3/n3) = 4 (nodos en diferentes racks del mismo datacenter)\n",
    "    - distancia (/d1/r1/n1, /d2/r3/n4) = 6 (nodos en diferentes datacenters)\n",
    "    \n",
    "## HDFS: rack-awareness\n",
    "- ¿Qué es un rack-awareness?\n",
    "    - Los rack son armarios donde se encuentran los servidores instalados\n",
    "    - Los servidores del mismo rack comparten una serie de servicios\n",
    "        - Switch de conexión a la red, alimentación, ventilación, ...\n",
    "    - Los fallos de esos servicios afectan a todos los servidores del rack\n",
    "    \n",
    "## HDFS: Resumen\n",
    "- HDFS explota el paralelismo del sistema para leer los ficheros con mayor rapidez (Write Once Read Many)\n",
    "- HDFS divide los ficheros en bloques de gran tamaño (normalmente 64,128M)\n",
    "    - Menor tamaño congestionaría el NameNode\n",
    "- Mejor pocos grandes ficheros\n",
    "- Formas de insertar datos en HDFS:\n",
    "    - Copiarlos manualmente\n",
    "    - Flume\n",
    "    - Sqoop\n",
    "    - ...\n",
    "    \n",
    "## HDFS: Problemas de la versión 1\n",
    "- En su versión 1.0, HDFS tenía los siguientes inconvenientes\n",
    "    - El namenode es único. Esto imnplica una serie de limitaciones entre las que destacan las siguientes:\n",
    "        - Número de ficheros almacenados. Esto se debe a que el NameNode mantiene los metadatos en memoria.\n",
    "        - Espacio de nombres único: esto provoca que el NameNode no puede delegar carga de trabajo por lo que se convierte en un cuello de botella\n",
    "        - Single Point of Failure (SPOF)\n",
    "    - Diseñado solamente para ejecutar aplicaciones MapReduce\n",
    "\n",
    "## HDFS: Federación de Namenodes\n",
    "- Para afrontar estos problemas, se propone la federación de NameNodes\n",
    "    - Permite tener espacios de nombres independientes\n",
    "    - Se elimina el SPOF\n",
    "    - Se permte mayor número de ficheros almacenados\n",
    "\n",
    "# MapReduce\n",
    "\n",
    "## ¿Qué es MapReduce?\n",
    "- MapReduce es un modelo de programación paralela distribuida enfocado a grandes conjuntos de datos procesados en un cluster\n",
    "- Automatiza la paralelización de las ejecuciones así como la distribución de las tareas entre los nodos\n",
    "- Tiene varias fases\n",
    "    - Map\n",
    "        - Opera en un único bloque de un fichero HDFS\n",
    "        - Se ejecuta siempre que sea posible en el nodo que almacena dicho bloque, lo que se minimiza el tráfico sobre la red.\n",
    "        - Salida: pares <clave, valor> -> Es importante seleccionar adecuadamente estos pares.\n",
    "    - Shuffle & sort\n",
    "        - Ordena y consolida los datos intermedios de todos los maps\n",
    "        - Sucede cuando todas las tareas map han acabado y antes de que comiencen las tareas reduce\n",
    "    - Reduce\n",
    "        - Opera sobre los resultados intermedios ordenados y barajados (la salida de las tareas map)\n",
    "        - Produce los resultados finales\n",
    "\n",
    "- MapReduce trata de minimizar las transferencias de información sobre la red para mejorar las prestaciones del sistema\n",
    "    - Los maps se ejecutan, en la medida de lo posible, en el mismo nodo que almacena el bloque\n",
    "- Automatiza la diseminación de las tareas a través de los nodos, la gestión de los fallos, ... de forma que el usuario solamente se tiene que concentrar en las funciones map y reduce\n",
    "\n",
    "## Comparación entre MapReduce y una Base de datos Distribuida\n",
    "\n",
    "|MapReduce + HDFS|BD distribuida|\n",
    "|---|---|\n",
    "|Ejecuta aplicaciones arbitrarias|Ejecución paralela de consultas SQL sobre un cluster|\n",
    "|Tipos de datos y formatos de almacenamientos variados|Esquema de datos y formato de almacenamiento  redefinido|\n",
    "|«Esquema» definido al leer|Esquema definido al escribir|\n",
    "|Tolera fallos, no reinicia tareas por un fallo|No tolera fallos, reinicia tareas por un fallo|\n",
    "|Extensible, se pueden implementar modelos de programación sobre él|No extensible, solamente soportan SQL|\n",
    "\n",
    "## Hadoop Streaming\n",
    "- Hadoop Streaming es una utilidad que se distribuye junto con MapReduce\n",
    "- Utiliza las entradas/salidas estándar de Unix (stdin & stdout)\n",
    "- Cuando Hadoop Streaming ejecuta un trabajo, cada tarea map se ejecuta en su propio proceso utilizando el ejecutable que se proporciona en la orden\n",
    "- Seguidamente, los ficheros de entrada se convierten en líneas de texto y se redireccionan a la entrada estándar del map\n",
    "- La salida map son pares <clave, valor>, donde las claves y valores se encuentran separados por un separador (por defecto, el tabulador)\n",
    "- Los reducers también se ejecutan en su propio proceso utilizando su propio ejecutable\n",
    "- La salida del map se ordena y se mezcla de forma que los pares <clave, valor> con la misma clave vayan al mismo reducer\n",
    "- La salida del reducer se redirecciona a stdout\n",
    "- Por tanto, para redactar tabajos MapReduce en Python utilizando Hadoop Streaming, hay que preparar dos ficheros con código Python: la función map y la función reduce\n",
    "- Ejemplo de contador de palabras en Python:\n",
    "[02_hadoop_1]:images/02_hadoop_1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "import sys\n",
    "\n",
    "#entrada de la entrada estandar STDIN\n",
    "for line insys.stdin:\n",
    "    # eliminamos espacios blancos al principio y final\n",
    "    line = line.trip()\n",
    "    # dividimos la linea en palabras\n",
    "    words = line.split()\n",
    "    # incrementamos los contadores\n",
    "    for word in words:\n",
    "        # escribimos los resultados a la salida estandar STDOUT\n",
    "        # Esta salida será la entrada para el reduce, es decir, par reducer01.py\n",
    "        # Delimitado por tab, para cada palabra ponemos 1 ocurrencia\n",
    "        print '%s\\t%s'(word,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "current_word=None\n",
    "current_count=0\n",
    "word=None\n",
    "\n",
    "# entrada desde STDIN\n",
    "for line in sys.stdin:\n",
    "    # eliminamos espacios blancos al principio y final\n",
    "    line = line.strip()\n",
    "    # pareamos la entrada que hemos obtenido del mapper01.py\n",
    "    word, count = line.split('\\t',1)\n",
    "    \n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "        else:\n",
    "            if current_word\n",
    "                print '%s\\t%s' % (current_word, current_count)\n",
    "            current_count = count\n",
    "            current_word = word\n",
    "    if current_word == word:\n",
    "        print '%s\\t%s' % (current_word, current_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejecutándolo en local (no usamos Hadoop)\n",
    "    - Creamos en local una carpeta llamada examplemapreduce y dejamos en ella los ficheros mapper01.py y reducer01.py\n",
    "    - Creamos un fichero de texto en esta carpeta, fichero.txt\n",
    "    > echo \"Hola esto es una prueba de un contador de palabras\" > fichero.txt\n",
    "    - Desde esa carpeta, ejecutamos:\n",
    "    > cat fichero.txt | ./mapper01.py | sort | ./reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejecutándolo en Hadoop:\n",
    "    - Partiendo de la carpeta y fichero de texto creados, creamos en HDFS una carpeta llamada examplemapreduce y cargamos en ella el fichero de texto\n",
    "        > hdfs dfs -mkdir examplemapreduce\n",
    "        >\n",
    "        > hdfs dfs -put fichero.txt examplemapreduce\n",
    "    - Ejecutamos el trabajo mapreduce de la siguiente forma;\n",
    "        > hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
    "        > \n",
    "        > -file mapper01.py, reducer01.py -mapper mapper01.py -reduce reducer01.py\n",
    "        >\n",
    "        > -input /path/to/examplemapreduce/*\n",
    "        >\n",
    "        > -output /path/to/examplemapreduce-output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspectos de diseño\n",
    "- Al diseñar programas MapReduce es necesario tener en cuenta algunos aspectos de diseño\n",
    "    - Utilizar un ``combiner``, entre el map y el reduce\n",
    "    - Elegir de forma apropiada las claves de los pares <clave, valor>\n",
    "    - Dedicir de forma inteligente dónde (en el map o el reduce) se implementa cada funcionalidad\n",
    "    - Tener en cuenta la localidad de los cálculos\n",
    "    \n",
    "## Combiner\n",
    "- Los map producen una gran cantidad de datos de salida que se tienen que enviuar por la red, barajar, oredenar y reducir\n",
    "    - Esto consume altas cantidades de ancho de banda de red, así como recuros (memoria, CPU) en el reducer\n",
    "- Para reducir el consumo de recursos, se utilizan los ``combinadores`` \n",
    "- Estos realizan cómputos sobre las salidas del map, en los nodos donde se ejecutan los map, antes de que se envíen por la red al reducer adecuado\n",
    "- Normalmente, el código del combiner es el mismo (o muy similar) al reducer\n",
    "\n",
    "## Partitioner\n",
    "- Normalmente las claves salida del map se envían a un reducer de forma aleatoria (los pares <clave, valor> con la misma clave van al mimso reducer\n",
    "    - ej.: Todos los pares <perro,1> van al reducer 1, todos los pares <gato, 1> van al reducer 2, etc\n",
    "- El problema viene cuando las claves no están equilibradas (hay muchos pares <clave,valor> con una determinada clave y muy pocos con otros).\n",
    "     - La mayor parte de los reducer estarán infrautilizados, mientras que el que reciba la clave popular estará sobrecargado\n",
    "- Es posible implementar un ``particionador`` que utilice alguna regla para dividir el espacio de valores de la clave, de forma que la carga de trabajo se reparta de forma más equitativa entre los reducers\n",
    "\n",
    "## Localidad de los cálculos\n",
    "- Map\n",
    "    - Puede haber tantos procesos map como nodos en el cluster\n",
    "    - Los map se ejecutan en la medida de lo posible, en los nodos del cluster que almacenan los datos de entrada\n",
    "- Reduce\n",
    "    - Puede haber tantos procesos reduce como claves distintas en la salida del map\n",
    "    - Los reduce se ejecutan en cualquier nodo del cluster\n",
    "        - Un reducer recibe todos los pares <clave, valor> para la misma clave\n",
    "    - Es recomendable poner la complejidad en el map y dejar el reduce lo más sencillo posible, para explotar el paralelismo\n",
    "\n",
    "## Patrones de diseño\n",
    "- Los patrones de diseño muestran estrategias genéricas que pueden ser de utilidad a la hora de afrontar un problema dado\n",
    "- Los principales patrones se pueden agrupar en las siguientes categorías\n",
    "    - Resúmenes\n",
    "        - Agrupa los datos de entrada en función de algún parámetro (hora, día y hora, usuario, ...) y calculan alguna característica de interés\n",
    "        - Los problemas que se resuelven con este patrón son:\n",
    "            - Resúmenes numéricos: conteos, máximo, mínimo, media, ...\n",
    "![02_hadoop_3]\n",
    "            - Índices invertidos: es importante cuando estamos desarrollando una herramienta de búsqueda para una nueva aplicación\n",
    "                - Ej.: en qué página se menciona una palabra\n",
    "![02_hadoop_4]\n",
    "    - Filtrado\n",
    "        - Crea subconjuntos de los datos basándose en un criterio sin modificar los datos originales\n",
    "            - Ej.: muestra los resultados del último año en un dataset que contiene datos de 10 años\n",
    "            - Tipos de filtrados:\n",
    "                 - Filtrado simple\n",
    "![02_hadoop_5]\n",
    "                 - Filtro bloom\n",
    "![02_hadoop_6]\n",
    "                 - Top N\n",
    "![02_hadoop_7]\n",
    "                 - Muestreo aleatorio\n",
    "    - Reuniones (joins)\n",
    "        - Es útil cuando tenemos distintos datasets que deseamos reunir utilizando una clave\n",
    "            - Operaciones de conjuntos\n",
    "![02_hadoop_8]\n",
    "            - Estructura del patrón reunión\n",
    "![02_hadoop_9]\n",
    "\n",
    "[02_hadoop_3]:images/02_hadoop_3.png\n",
    "[02_hadoop_4]:images/02_hadoop_4.png\n",
    "[02_hadoop_5]:images/02_hadoop_5.png\n",
    "[02_hadoop_6]:images/02_hadoop_6.png\n",
    "[02_hadoop_7]:images/02_hadoop_7.png\n",
    "[02_hadoop_8]:images/02_hadoop_8.png\n",
    "[02_hadoop_9]:images/02_hadoop_9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRJob\n",
    "\n",
    "- Es una librería de Python que permite la programación de trabajos MapReduce\n",
    "- Permite la ejecución de dichos protgramas MapReduce tanto localmente, como en cluster, como en una variedad de servicios en la Nube (Amazon / Google)\n",
    "- Se basa en Hadoop Streaming para la ejecución de trabajos\n",
    "\n",
    "- Ventajas\n",
    "    - El código de Python no cambia sin importar que estemos trabajando en local, hadoop o nube\n",
    "    - Su ejecución local permite depurar el código de forma más sencilla que si se ejecuta en un cluster\n",
    "    - Amplia documentación, desarrollos open-source actualizados\n",
    "\n",
    "## MRJob: protocolos de entrada, salida e interno\n",
    "\n",
    "- Los datos que entran en el map, pasan del map al reduce y salen del reduce, siguen un protocolo que define la forma en que se codifican tales datos\n",
    "- Por defecto\n",
    "    - INPUT_PROTOCOL = RawValueProtocol\n",
    "    - INTERNAL_PROTOCOL = JSONProtocol\n",
    "    - OUTPUT_PROTOCOL = JSONProtocol\n",
    "- Otras opciones\n",
    "    - ReprProtocol: Representa cada par <clave, valor> como una representación imprimible\n",
    "    - PickleProtocol: Utiliza la función pickle de Python para representrar los pares <clave, valor>\n",
    "- MRJob permite  que en la llamada se incluyan parámetros de entrada\n",
    "- Se puede realizar una ordenación secundaria\n",
    "    - Consiste en que los reducers reciban los pares <clave, valor> se encuentren ordenados por valor\n",
    "    - Para activarla\n",
    "        > SORT_VALUES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
